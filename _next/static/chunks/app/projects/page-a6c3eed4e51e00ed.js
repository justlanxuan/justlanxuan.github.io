(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[893],{429:(e,t,n)=>{Promise.resolve().then(n.bind(n,809))},809:(e,t,n)=>{"use strict";n.r(t),n.d(t,{default:()=>l});var i=n(5155),s=n(2115),a=n(2619),o=n.n(a);let r={title:"Projects",items:[{title:"My First ELEC Project",slug:"elec1100-project",tags:["sensor","circuit"],date:"2024-05-02",image:"/img/elec1100-cover.png",description:"autonomous line‑tracking mobile robot car, based on Arduino Nano",content:'\n## Overview\n\nThis project focuses on developing an **autonomous line‑tracking mobile robot car**. This page presents the design and implementation of of an Arduino Nano–based system that integrates infrared sensors, motor speed control and efficient embedded logic to achieve autonomous navigation. The system detects a white line on a dark surface and navigates the path accurately by adjusting the rotation speed of two DC motors. The robot is capable of making directional turns, stopping, and performing complex maneuvers such as 180\xb0 and 360\xb0 rotations based on real‑time sensor input.\n<figure class="img-row">\n<div class="img-wrap">\n  <img src="/project/car3.jpg">\n  <img src="/project/car4.png">\n</div>\n  <figcaption>The map and car for testing</figcaption>\n</figure>\nThe 3 primary modules:\n\n- Sensing Unit:\n**Infrared reflectance sensors** detect the surface contrast between the white track and the dark background. These sensors provide continuous feedback to the microcontroller for navigation decisions.\n\n- Control Unit\nThe **Arduino Nano** processes input from the sensors and generates control signals based on predefined logic. This unit determines motor direction and speed using PWM (pulse‑width modulation) signals.\n\n- Actuator Unit\nA **motor driver (L293D)** receives PWM signals and direction commands to control the left and right DC motors. It enables bidirectional motor motion and smooth speed regulation.\n<figure class="img-row">\n<div class="img-wrap">\n  <img src="/project/car1.jpg">\n  <img src="/project/car2.jpg">\n</div>\n  <figcaption>Circuit Design</figcaption>\n</figure>\n\n## Takeaways\n\n\n'},{title:"A tactile Sensor Design",slug:"tactile-sensor",tags:["sensor","fabrication","algorithm"],date:"2025-05-29",image:"/img/tactile-sensor-cover.jpg",description:"A highly robust contact sensor for precise contact detection of fabric",content:'This project is published on ICRA 2025: [A Highly Robust Contact Sensor for Precise Contact Detection of Fabric](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11127921) (co‑first author). This page provides additional notes, ideas, and ongoing thoughts related to the project.\n\n## Overview\nAutomation in the apparel and textile industry has long been a pursuit. However, accurately locating the surface of a fabric remains a challenge, limiting the automation in sorting, packaging, and other processes. When humans locate clothing, they rely on contact feedback for the exact position of the clothing surface. As existing contact detection solutions are significantly affected by environmental factors, it is essential to develop a sensor with robust contact detection capabilities. In this work, we introduce a contact sensor with high robustness and high force resolution. This contact sensor detects contact by measuring the deformation of an elastomer using a distancemeasuring module. Based on the deformation characteristics of the elastomer, we designed a detection algorithm that not only reduces the noise of data but also extracts features such as trends and elastomer states, enabling reliable contact detection. Through experiments, we validated that this contact sensor can detect contact forces as low as 0.017 N and is robust to external interference or sensor movement. We also verified that the sensor can process data within 7.5 ms and return contact detection with 95% accuracy. Additionally, we assessed its effectiveness in real fabric contact scenarios.\n<figure>\n  <img src="/project/sensor7.png">\n  <figcaption>The whole system</figcaption>\n</figure>\n\n## Some Intuitive Ideas\nIn the context of fabric detection, a sensor must be **robust** in industrial environments while providing **accurate, real-time feedback**. One of the main challenges in fabric detection is that fabric is very soft and easily deforms. As a result, a rigid sensor must offer extremely high spatial resolution and very low latency to detect contact before substantial deformation occurs. (Latency is a critical issue because fabric can deform very quickly under even a small force.)\n\n\nAn intuitive idea that follows from this observation is that if the sensor itself is <span style="color:rgb(150, 0, 0);">**"softer"**</span> than the fabric, the fabric will be less prone to deformation upon contact. This, in turn, allows more time for the system to detect contact while maintaining a small interaction force.\n\nAnother intuitive idea is that, since the sensor is "softer" than the fabric, it will deform more than the fabric during contact, making this deformation <span style="color:rgb(150, 0, 0);">**observable**</span> in the sensor’s output. (In fact, we found that deformation in a soft object is easier to detect and more observable than the applied force itself.)\n\nThe final structure of the sensor follows the above ideas: it\'s soft(with a soft membrane structure) and observe detection via deformation(with an internal optic distance sensor to detect deformation of that soft membrane).\n\n## Fabrication\nThere\'s nothing interesting about the optic distance sensor: it is a standard time-of-flight (ToF) module with a relatively wide field of view (FoV) and relatively high spatial resolution, particularly at short range.\n<figure>\n  <img src="/project/sensor6.jpg">\n  <figcaption>Optic sensor without the cover (I took it off to see how it works)</figcaption>\n</figure>\nThe design of the soft membrane is more interesting: it must be softer than the fabric, yet it should maintain its shape (i.e., remain undeformed) during motion or under disturbances such as wind. After several experiments, I found that a 0.4 mm‑thick silicone gel membrane, formed into cylindrical and hemispherical shapes, is the softest configuration that can still maintain sufficient stiffness and shape stability.\n<figure class="img-row">\n<div class="img-wrap">\n  <img src="/project/sensor1.png" style="width: 30%;">\n  <img src="/project/sensor5.jpg" style="width: 55%;">\n</div>\n  <figcaption>Different structures that I came up with</figcaption>\n</figure>\n<figure class="img-row">\n<div class="img-wrap">\n  <img src="/project/sensor2.png"style="width: 55%;">\n  <img src="/project/sensor4.png"style="width: 30%;">\n</div>\n  <figcaption>Testing different thicknesses & final 3D mold for casting the soft membrane</figcaption>\n</figure>\n\nA **tip** for fabricating a soft membrane is to design a proper fixing structure for the 3D mold that holds the mold securely in place. This helps ensure that the membrane maintains a uniform thickness in all directions. Consistent thickness is crucial for subsequent property analysis and algorithm design, as variations in thickness can significantly influence its performance.\n\n## Algorithhm Design\nThe raw distance data from the sensor is processed by a designed Kalman Filter (which is not really interesting). The logic is also straightforward: when the distance (between the membrane and the sensor) decreases, it indicates that contact is occurring. The interesting challenge lies in finding the right trade‑off between <span style="color:rgb(150, 0, 0);">**accuracy**</span> and <span style="color:rgb(150, 0, 0);">**sensitivity**</span>.\n\nA naive solution:\n- Accuracy comes first: collect more evidence before confirming a “touch” to ensure that only genuine contact is detected.\n- Sensitivity comes first: Identify contact with fewer “touch” signals, allowing faster detection but at the risk of false positives.\n\n### Sensitivity\nBut how sensitive should it be? A common way is to detect the force resolution. Another important standard in this context is that the membrane should detect contact <span style="color:rgb(150, 0, 0);">**before the fabric gets compressed**</span>. Ideally, it should sense the touch while still preserving the fabric’s natural “fluffy” texture, without flattening it.\n\n### Accuracy\nBy studying how the membrane physically interacts with the fabric, I found some interesting clues that support the classifier, which was developed using a mix of data‑driven methods and physical modeling.\n\nAn interesting observation: when membrane is disturbed by something light, the top surface only forms a slight indentation. But when a stronger force is applied, such as contact from clothing, especially when pressed, the bottom part of the membrane also deforms. This creates a non‑linear link between force and deformation.\n<figure>\n  <img src="/project/sensor8.png">\n  <figcaption>How the membrane deforms with different force applied</figcaption>\n</figure>\n\n## Takeaways\n\n- A more solid structure from inside?\n- Without touching?'},{title:"Data Visualization",slug:"vis",tags:["web","vis & hci"],date:"2024-11-28",image:"/img/vis-cover.png",description:"How does caffeine affect us: an interactive story-telling visualization design.",content:"\n## Overview"}]};var c=n(8185);function l(){let[e,t]=(0,s.useState)("All"),n=Array.from(new Set(["All",...r.items.flatMap(e=>e.tags||[])])),a="All"===e?r.items:r.items.filter(t=>(t.tags||[]).includes(e));return(0,i.jsxs)(c.A,{title:r.title,children:[(0,i.jsx)("div",{className:"filter-buttons",children:n.map(n=>(0,i.jsx)("button",{className:"filter-btn ".concat(e===n?"active":""),onClick:()=>t(n),children:n},n))}),(0,i.jsx)("div",{className:"projects-grid",children:a.map((e,t)=>(0,i.jsxs)(o(),{href:"/projects/".concat(e.slug),className:"project-card",children:[(0,i.jsx)("div",{className:"card-image",style:{backgroundImage:"url(".concat(e.image,")")}}),(0,i.jsxs)("div",{className:"card-content",children:[(0,i.jsx)("h3",{children:e.title}),(0,i.jsx)("p",{className:"project-description",children:e.description})]})]},t))})]})}},8185:(e,t,n)=>{"use strict";n.d(t,{A:()=>s});var i=n(5155);function s(e){let{title:t,children:n}=e;return(0,i.jsxs)("div",{className:"page-layout",children:[t&&(0,i.jsx)("h1",{className:"page-title",children:t}),(0,i.jsx)("div",{className:"page-content",children:n})]})}}},e=>{e.O(0,[619,441,255,358],()=>e(e.s=429)),_N_E=e.O()}]);